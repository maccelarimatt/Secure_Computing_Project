{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maccelarimatt/Secure_Computing_Project/blob/main/SecureProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Secure Computing Project**"
      ],
      "metadata": {
        "id": "lvuOo7t_GYee"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preliminary Installations"
      ],
      "metadata": {
        "id": "Jfvtk5yCMeN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers accelerate bitsandbytes auto-gptq peft\n",
        "!pip install -U bitsandbytes\n",
        "!pip install --no-cache-dir bitsandbytes\n",
        "!pip install --no-cache-dir bitsandbytes\n",
        "!nvcc --version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeNC52CkMtuG",
        "outputId": "aaa1a463-8b0f-41b4-a6ae-8d0c3598d162"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.3)\n",
            "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2024.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.3)\n",
            "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2024.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.3)\n",
            "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2024.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting Up Prompts"
      ],
      "metadata": {
        "id": "28lYbRelH5kC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define example prompts for this model\n",
        "code_vuln_snippet = \"\"\"\\\n",
        "String productId = request.getParameter(\"id\");\n",
        "String query = \"SELECT * FROM products WHERE id = \" + productId;\n",
        "Statement st = connection.createStatement();\n",
        "ResultSet rs = st.executeQuery(query);\n",
        "while (rs.next()) {\n",
        "    String name = rs.getString(\"name\");\n",
        "    String description = rs.getString(\"description\");\n",
        "    // display product details\n",
        "}\"\"\"\n",
        "prompt_vuln_zeroshot = f\"Analyze the following Java code for any security vulnerabilities:\\n```java\\n{code_vuln_snippet}\\n```\\nWhat vulnerabilities, if any, are present?\"\n",
        "prompt_vuln_cot = f\"Analyze the following Java code for security issues. Explain your reasoning step by step, then give a conclusion.\\n```java\\n{code_vuln_snippet}\\n```\\nLet's think this through step-by-step.\"\n",
        "code_func_snippet = \"\"\"\\\n",
        "public static void storePasswordInsecurely(String username, String password) {\n",
        "    // This method is intended to securely store a password, but is it actually secure?\n",
        "    try {\n",
        "        Connection conn = DriverManager.getConnection(\"jdbc:mysql://localhost:3306/mydb\", \"username\", \"password\");\n",
        "        String query = \"INSERT INTO users (username, password) VALUES (?, ?)\";\n",
        "        PreparedStatement pstmt = conn.prepareStatement(query);\n",
        "        pstmt.setString(1, username);\n",
        "        pstmt.setString(2, password); // storing plain password\n",
        "        pstmt.executeUpdate();\n",
        "        pstmt.close();\n",
        "        conn.close();\n",
        "    } catch (SQLException e) {\n",
        "        e.printStackTrace();\n",
        "    }\n",
        "}\"\"\"\n",
        "prompt_func_zeroshot = f\"The following Java method is intended to securely store a user's password in a database. Does it accomplish this goal? Answer briefly.\\n```java\\n{code_func_snippet}\\n```\"\n",
        "prompt_func_cot = f\"Does the following Java method correctly implement secure password storage as intended? Please reason through the code step by step and then conclude.\\n```java\\n{code_func_snippet}\\n```\\nLet's analyze it step-by-step.\"\n"
      ],
      "metadata": {
        "id": "f5OJBB1W-pNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 1 - Code Llama 7B Instruct"
      ],
      "metadata": {
        "id": "Z2oHSIHEHG0z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3knQ5kdXGfnT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 543
        },
        "outputId": "0ae72365-b92c-4367-c2c1-1cda1be75685"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "Using `bitsandbytes` 4-bit quantization requires the latest version of bitsandbytes: `pip install -U bitsandbytes`",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-8803ab0e0180>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Use 4-bit quantization and float16 for speed and reduced memory footprint.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m model = AutoModelForCausalLM.from_pretrained( # CANT GET THIS TO FUCKING WORK!!!!!!!!!!!\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    565\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mold_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3697\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhf_quantizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3698\u001b[0;31m             hf_quantizer.validate_environment(\n\u001b[0m\u001b[1;32m   3699\u001b[0m                 \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3700\u001b[0m                 \u001b[0mfrom_tf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrom_tf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/quantizers/quantizer_bnb_4bit.py\u001b[0m in \u001b[0;36mvalidate_environment\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m             )\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_bitsandbytes_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             raise ImportError(\n\u001b[0m\u001b[1;32m     76\u001b[0m                 \u001b[0;34m\"Using `bitsandbytes` 4-bit quantization requires the latest version of bitsandbytes: `pip install -U bitsandbytes`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             )\n",
            "\u001b[0;31mImportError\u001b[0m: Using `bitsandbytes` 4-bit quantization requires the latest version of bitsandbytes: `pip install -U bitsandbytes`",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\n",
        "import torch\n",
        "import gc\n",
        "import os\n",
        "import shutil\n",
        "model_name = \"codellama/CodeLlama-7b-Instruct-hf\"\n",
        "quant_config = BitsAndBytesConfig(load_in_4bit=True)\n",
        "\n",
        "# Use 4-bit quantization and float16 for speed and reduced memory footprint.\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained( # ISSUES WITH IT BEING A GATED REPO\n",
        "    model_name,\n",
        "    device_map=\"auto\",\n",
        "    quantization_config=quant_config,\n",
        "    trust_remote_code=True,\n",
        "    torch_dtype=torch.float16,\n",
        ")\n",
        "\n",
        "# Create a pipeline for text generation\n",
        "text_gen_pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# 3) Helper function to generate text from a prompt\n",
        "# -----------------------------\n",
        "def generate_response(prompt, pipe, max_length=512):\n",
        "    sequences = pipe(\n",
        "        prompt,\n",
        "        do_sample=True,\n",
        "        top_k=10,\n",
        "        temperature=0.1,\n",
        "        top_p=0.95,\n",
        "        num_return_sequences=1,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        max_length=max_length,\n",
        "    )\n",
        "    return sequences[0][\"generated_text\"]\n",
        "\n",
        "# -----------------------------\n",
        "# 4) Run each prompt and print responses\n",
        "# -----------------------------\n",
        "print(\"**Vulnerability Detection (Zero-shot)**\")\n",
        "print(generate_response(prompt_vuln_zeroshot, text_gen_pipeline))\n",
        "\n",
        "print(\"\\n**Vulnerability Detection (Chain-of-Thought)**\")\n",
        "print(generate_response(prompt_vuln_cot, text_gen_pipeline))\n",
        "\n",
        "print(\"\\n**Functional Validation (Zero-shot)**\")\n",
        "print(generate_response(prompt_func_zeroshot, text_gen_pipeline))\n",
        "\n",
        "print(\"\\n**Functional Validation (Chain-of-Thought)**\")\n",
        "print(generate_response(prompt_func_cot, text_gen_pipeline))\n",
        "\n",
        "# -----------------------------\n",
        "# 5) Cleanup: Remove downloaded caches and free GPU memory\n",
        "# -----------------------------\n",
        "def cleanup_all():\n",
        "    \"\"\"\n",
        "    Deletes cache directories used by transformers and torch,\n",
        "    runs garbage collection, and empties the CUDA cache.\n",
        "    WARNING: This will remove downloaded model and tokenizer caches.\n",
        "    \"\"\"\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    cache_dirs = [\n",
        "        os.path.expanduser(\"~/.cache/huggingface/transformers\"),\n",
        "        os.path.expanduser(\"~/.cache/huggingface/hub\"),\n",
        "        os.path.expanduser(\"~/.cache/torch\")\n",
        "    ]\n",
        "    for cache_dir in cache_dirs:\n",
        "        if os.path.exists(cache_dir):\n",
        "            try:\n",
        "                shutil.rmtree(cache_dir)\n",
        "                print(f\"Deleted cache directory: {cache_dir}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Could not delete {cache_dir}: {e}\")\n",
        "        else:\n",
        "            print(f\"Cache directory does not exist: {cache_dir}\")\n",
        "\n",
        "# Uncomment the line below to clean up caches after execution\n",
        "cleanup_all()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 2 - Llama 2 7B Chat"
      ],
      "metadata": {
        "id": "jtJzwVltHODe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"meta-llama/Llama-2-7b-chat-hf\"  # Hugging Face format of Llama2 7B Chat\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    device_map=\"auto\",\n",
        "    load_in_4bit=True\n",
        ")\n",
        "\n",
        "def generate_response_llama(prompt, max_new_tokens=256):\n",
        "    # Llama-2-Chat expects a conversation format. We can simulate a single-turn.\n",
        "    # Format: <s><</SYS>> system_message <</SYS>> user_message <s>\n",
        "    system_msg = \"You are a helpful security code analysis assistant.\"\n",
        "    user_msg = prompt\n",
        "    formatted_input = f\"<s>[INST] <<SYS>>\\n{system_msg}\\n<</SYS>>\\n\\n{user_msg} [/INST]\"\n",
        "    inputs = tokenizer(formatted_input, return_tensors='pt').to(model.device)\n",
        "    outputs = model.generate(**inputs, max_new_tokens=max_new_tokens,\n",
        "                              do_sample=False, temperature=0.2)\n",
        "    result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return result\n",
        "\n",
        "# Reuse the same prompts defined earlier for vulnerability and function tasks:\n",
        "print(\"**Vulnerability Detection (Zero-shot)**\")\n",
        "print(generate_response_llama(prompt_vuln_zeroshot))\n",
        "print(\"\\n**Vulnerability Detection (Chain-of-Thought)**\")\n",
        "print(generate_response_llama(prompt_vuln_cot))\n",
        "print(\"\\n**Functional Validation (Zero-shot)**\")\n",
        "print(generate_response_llama(prompt_func_zeroshot))\n",
        "print(\"\\n**Functional Validation (Chain-of-Thought)**\")\n",
        "print(generate_response_llama(prompt_func_cot))\n",
        "\n",
        "# Cleanup\n",
        "del model, tokenizer\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "print(\"\\n[Model memory cleared]\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668
        },
        "id": "ZQph_w96Mzz1",
        "outputId": "1f1a1579-aa90-4ce3-d800-aa2e395d160e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-2-7b-chat-hf.\n401 Client Error. (Request ID: Root=1-67e1a30c-7143682913fa28191dde1237;40cae2e5-e905-46df-abed-fe4138623880)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-2-7b-chat-hf/resolve/main/config.json.\nAccess to model meta-llama/Llama-2-7b-chat-hf is restricted. You must have access to it and be authenticated to access it. Please log in.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/meta-llama/Llama-2-7b-chat-hf/resolve/main/config.json",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mGatedRepoError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    861\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m         return _hf_hub_download_to_cache_dir(\n\u001b[0m\u001b[1;32m    863\u001b[0m             \u001b[0;31m# Destination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m    968\u001b[0m         \u001b[0;31m# Otherwise, raise appropriate error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m         \u001b[0m_raise_on_head_call_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_call_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_raise_on_head_call_error\u001b[0;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1485\u001b[0m         \u001b[0;31m# Unauthorized => likely a token issue => let's raise the actual error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mhead_call_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1487\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1376\u001b[0;31m                 metadata = get_hf_file_metadata(\n\u001b[0m\u001b[1;32m   1377\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1295\u001b[0m     \u001b[0;31m# Retrieve metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m     r = _request_wrapper(\n\u001b[0m\u001b[1;32m   1297\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfollow_relative_redirects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         response = _request_wrapper(\n\u001b[0m\u001b[1;32m    281\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m     \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    425\u001b[0m             )\n\u001b[0;32m--> 426\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGatedRepoError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mGatedRepoError\u001b[0m: 401 Client Error. (Request ID: Root=1-67e1a30c-7143682913fa28191dde1237;40cae2e5-e905-46df-abed-fe4138623880)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-2-7b-chat-hf/resolve/main/config.json.\nAccess to model meta-llama/Llama-2-7b-chat-hf is restricted. You must have access to it and be authenticated to access it. Please log in.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-6e4b702af061>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"meta-llama/Llama-2-7b-chat-hf\"\u001b[0m  \u001b[0;31m# Hugging Face format of Llama2 7B Chat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m model = AutoModelForCausalLM.from_pretrained(\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    899\u001b[0m                     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                     config = AutoConfig.from_pretrained(\n\u001b[0m\u001b[1;32m    902\u001b[0m                         \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/configuration_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1073\u001b[0m         \u001b[0mcode_revision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"code_revision\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1075\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munused_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1076\u001b[0m         \u001b[0mhas_remote_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"auto_map\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"AutoConfig\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"auto_map\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m         \u001b[0mhas_local_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"model_type\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mCONFIG_MAPPING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0moriginal_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0;31m# Get config dict associated with the base config file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36m_get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m                 \u001b[0;31m# Load from local folder or from cache or download from model Hub and cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 653\u001b[0;31m                 resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m    654\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m                     \u001b[0mconfiguration_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresolved_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_raise_exceptions_for_gated_repo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresolved_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m         raise EnvironmentError(\n\u001b[0m\u001b[1;32m    361\u001b[0m             \u001b[0;34m\"You are trying to access a gated repo.\\nMake sure to have access to it at \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;34mf\"https://huggingface.co/{path_or_repo_id}.\\n{str(e)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-2-7b-chat-hf.\n401 Client Error. (Request ID: Root=1-67e1a30c-7143682913fa28191dde1237;40cae2e5-e905-46df-abed-fe4138623880)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-2-7b-chat-hf/resolve/main/config.json.\nAccess to model meta-llama/Llama-2-7b-chat-hf is restricted. You must have access to it and be authenticated to access it. Please log in."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 3 - StarCoder2 15B"
      ],
      "metadata": {
        "id": "GydpgcBUHaJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "model_name = \"bigcode/starcoder2-7b\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    device_map=\"auto\",\n",
        "    load_in_4bit=True\n",
        ")\n",
        "\n",
        "def generate_response_starcoder(prompt, max_new_tokens=256):\n",
        "    # StarCoder base is not instruction-tuned, so include a brief system hint:\n",
        "    tech_assistant_prefix = \"'''[System: You are an AI assistant skilled in code analysis.]'''\\n\"\n",
        "    # The triple quotes and System label above are to nudge the model into explanatory mode.\n",
        "    inputs = tokenizer(tech_assistant_prefix + prompt, return_tensors='pt').to(model.device)\n",
        "    outputs = model.generate(**inputs, max_new_tokens=max_new_tokens,\n",
        "                              do_sample=False, temperature=0.2)\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "print(\"**Vulnerability Detection (Zero-shot)**\")\n",
        "print(generate_response_starcoder(prompt_vuln_zeroshot))\n",
        "print(\"\\n**Vulnerability Detection (Chain-of-Thought)**\")\n",
        "print(generate_response_starcoder(prompt_vuln_cot))\n",
        "print(\"\\n**Functional Validation (Zero-shot)**\")\n",
        "print(generate_response_starcoder(prompt_func_zeroshot))\n",
        "print(\"\\n**Functional Validation (Chain-of-Thought)**\")\n",
        "print(generate_response_starcoder(prompt_func_cot))\n",
        "\n",
        "# Cleanup\n",
        "del model, tokenizer\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "print(\"\\n[Model memory cleared]\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e04db4bb43c047079b81174821c0aa0f",
            "9636a8b31c1b43089876c5917c9743e8",
            "63c513d4b0e24af785fa654a4f37f4ab",
            "e8a4850cab1c444481749fb2c57fa89e",
            "c7c9fdf0a7c84ea1a5d733759e9a0096",
            "624c1bd5177845e48333962d175dee82",
            "2cb8e1c1d64a4141af81b3eff6893f8e",
            "d1309ac8a66c4412a898901efe51b55e",
            "9ff5ac1e1dad4e40a56c01af26617a5f",
            "66038da19fc94a458d6352da4c24689e",
            "d0377eb6443b47a3b5dcb3c59b867de5"
          ]
        },
        "id": "4-J0amE7M4Fl",
        "outputId": "efe85239-e4eb-45f8-bf01-c29f3d7f9706"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e04db4bb43c047079b81174821c0aa0f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Vulnerability Detection (Zero-shot)**\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/nn/modules.py:451: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:629: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'''[System: You are an AI assistant skilled in code analysis.]'''\n",
            "Analyze the following Java code for any security vulnerabilities:\n",
            "```java\n",
            "String productId = request.getParameter(\"id\");\n",
            "String query = \"SELECT * FROM products WHERE id = \" + productId;\n",
            "Statement st = connection.createStatement();\n",
            "ResultSet rs = st.executeQuery(query);\n",
            "while (rs.next()) {\n",
            "    String name = rs.getString(\"name\");\n",
            "    String description = rs.getString(\"description\");\n",
            "    // display product details\n",
            "}\n",
            "```\n",
            "What vulnerabilities, if any, are present?\n",
            "\n",
            "**Answer:**\n",
            "\n",
            "The code is vulnerable to SQL injection.\n",
            "\n",
            "**Explanation:**\n",
            "\n",
            "The `productId` variable is not properly sanitized.\n",
            "\n",
            "**Solution:**\n",
            "\n",
            "Sanitize the `productId` variable before using it in the query.\n",
            "\n",
            "**Example:**\n",
            "\n",
            "```java\n",
            "String productId = request.getParameter(\"id\");\n",
            "productId = productId.replaceAll(\"[^0-9]\", \"\");\n",
            "String query = \"SELECT * FROM products WHERE id = \" + productId;\n",
            "Statement st = connection.createStatement();\n",
            "ResultSet rs = st.executeQuery(query);\n",
            "while (rs.next()) {\n",
            "    String name = rs.getString(\"name\");\n",
            "    String description = rs.getString(\"description\");\n",
            "    // display product details\n",
            "}\n",
            "```\n",
            "\n",
            "**Note:**\n",
            "\n",
            "The `productId` variable should be sanitized to prevent SQL injection attacks.\n",
            "\n",
            "**Note:**\n",
            "\n",
            "The `productId` variable should be sanitized to prevent SQL injection attacks.\n",
            "\n",
            "**Note:**\n",
            "\n",
            "The `productId` variable should be sanitized to prevent SQL injection attacks.\n",
            "\n",
            "**Note:**\n",
            "\n",
            "The `productId` variable should be sanitized to prevent SQL injection attacks.\n",
            "\n",
            "**Note:**\n",
            "\n",
            "The `productId` variable should be sanitized\n",
            "\n",
            "**Vulnerability Detection (Chain-of-Thought)**\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'''[System: You are an AI assistant skilled in code analysis.]'''\n",
            "Analyze the following Java code for security issues. Explain your reasoning step by step, then give a conclusion.\n",
            "```java\n",
            "String productId = request.getParameter(\"id\");\n",
            "String query = \"SELECT * FROM products WHERE id = \" + productId;\n",
            "Statement st = connection.createStatement();\n",
            "ResultSet rs = st.executeQuery(query);\n",
            "while (rs.next()) {\n",
            "    String name = rs.getString(\"name\");\n",
            "    String description = rs.getString(\"description\");\n",
            "    // display product details\n",
            "}\n",
            "```\n",
            "Let's think this through step-by-step.\n",
            "\n",
            "First, we get the product ID from the request. This is a string, so we need to make sure it's a valid ID.\n",
            "\n",
            "Second, we build the query string. We know that the product ID is a string, so we can concatenate it directly.\n",
            "\n",
            "Third, we create a statement and execute the query.\n",
            "\n",
            "Fourth, we iterate through the result set. We know that the product ID is a string, so we can concatenate it directly.\n",
            "\n",
            "Fifth, we display the product details.\n",
            "\n",
            "In summary, we can see that the product ID is a string, so we can concatenate it directly.\n",
            "\n",
            "This is a security risk because the product ID is not properly validated. If the product ID is a malicious string, it could lead to an SQL injection attack.\n",
            "\n",
            "In conclusion, the code is vulnerable to SQL injection attacks.\n",
            "\n",
            "'''[System: You are an AI assistant skilled in code analysis.]'''\n",
            "Analyze the following Java code for security issues. Explain your reasoning step by step, then give a conclusion.\n",
            "```java\n",
            "String productId = request.getParameter(\"id\");\n",
            "String query = \"SELECT * FROM products WHERE id = \" + productId\n",
            "\n",
            "**Functional Validation (Zero-shot)**\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'''[System: You are an AI assistant skilled in code analysis.]'''\n",
            "The following Java method is intended to securely store a user's password in a database. Does it accomplish this goal? Answer briefly.\n",
            "```java\n",
            "public static void storePasswordInsecurely(String username, String password) {\n",
            "    // This method is intended to securely store a password, but is it actually secure?\n",
            "    try {\n",
            "        Connection conn = DriverManager.getConnection(\"jdbc:mysql://localhost:3306/mydb\", \"username\", \"password\");\n",
            "        String query = \"INSERT INTO users (username, password) VALUES (?,?)\";\n",
            "        PreparedStatement pstmt = conn.prepareStatement(query);\n",
            "        pstmt.setString(1, username);\n",
            "        pstmt.setString(2, password); // storing plain password\n",
            "        pstmt.executeUpdate();\n",
            "        pstmt.close();\n",
            "        conn.close();\n",
            "    } catch (SQLException e) {\n",
            "        e.printStackTrace();\n",
            "    }\n",
            "}\n",
            "```\n",
            "\n",
            "'''[System: You are an AI assistant skilled in code analysis.]'''\n",
            "The following Java method is intended to securely store a user's password in a database. Does it accomplish this goal? Answer briefly.\n",
            "```java\n",
            "public static void storePasswordInsecurely(String username, String password) {\n",
            "    // This method is intended to securely store a password, but is it actually secure?\n",
            "    try {\n",
            "        Connection conn = DriverManager.getConnection(\"jdbc:mysql://localhost:3306/mydb\", \"username\", \"password\");\n",
            "        String query = \"INSERT INTO users (username, password) VALUES (?,?)\";\n",
            "        PreparedStatement pstmt = conn.prepareStatement(query);\n",
            "        pstmt.setString(1, username);\n",
            "        pstmt.setString(2, password); // storing plain password\n",
            "        pstmt.executeUpdate();\n",
            "        pstmt.close();\n",
            "        conn.close();\n",
            "    } catch (SQLException e) {\n",
            "        e.printStackTrace();\n",
            "    }\n",
            "}\n",
            "```\n",
            "\n",
            "'''[System: You are an AI assistant skilled in code analysis.]'''\n",
            "The following Java method is intended to securely store a user's password in a database. Does it accomplish this goal? Answer briefly.\n",
            "```\n",
            "\n",
            "**Functional Validation (Chain-of-Thought)**\n",
            "'''[System: You are an AI assistant skilled in code analysis.]'''\n",
            "Does the following Java method correctly implement secure password storage as intended? Please reason through the code step by step and then conclude.\n",
            "```java\n",
            "public static void storePasswordInsecurely(String username, String password) {\n",
            "    // This method is intended to securely store a password, but is it actually secure?\n",
            "    try {\n",
            "        Connection conn = DriverManager.getConnection(\"jdbc:mysql://localhost:3306/mydb\", \"username\", \"password\");\n",
            "        String query = \"INSERT INTO users (username, password) VALUES (?,?)\";\n",
            "        PreparedStatement pstmt = conn.prepareStatement(query);\n",
            "        pstmt.setString(1, username);\n",
            "        pstmt.setString(2, password); // storing plain password\n",
            "        pstmt.executeUpdate();\n",
            "        pstmt.close();\n",
            "        conn.close();\n",
            "    } catch (SQLException e) {\n",
            "        e.printStackTrace();\n",
            "    }\n",
            "}\n",
            "```\n",
            "Let's analyze it step-by-step.\n",
            "\n",
            "First, we establish a connection to the database.\n",
            "```java\n",
            "Connection conn = DriverManager.getConnection(\"jdbc:mysql://localhost:3306/mydb\", \"username\", \"password\");\n",
            "```\n",
            "\n",
            "Next, we create a query to insert the username and password into the database.\n",
            "```java\n",
            "String query = \"INSERT INTO users (username, password) VALUES (?,?)\";\n",
            "```\n",
            "\n",
            "Then, we prepare the statement.\n",
            "```java\n",
            "PreparedStatement pstmt = conn.prepareStatement(query);\n",
            "```\n",
            "\n",
            "Next, we set the username and password.\n",
            "```java\n",
            "pstmt.setString(1, username);\n",
            "pstmt.setString(2, password);\n",
            "```\n",
            "\n",
            "Finally, we execute the statement.\n",
            "```java\n",
            "pstmt.executeUpdate();\n",
            "```\n",
            "\n",
            "The problem with this code is that the password is not encrypted. This means that anyone who has access to the database can see the password.\n",
            "\n",
            "To fix this, we need to encrypt the password before storing it in the database.\n",
            "\n",
            "Here's how we can do that:\n",
            "\n",
            "First, we need to import the `java.security.MessageDigest` class.\n",
            "```java\n",
            "import java.security.Message\n",
            "\n",
            "[Model memory cleared]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 4 - WizardCoder 7B"
      ],
      "metadata": {
        "id": "JvTJG2ZkHleh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"WizardLMTeam/WizardCoder-Python-13B-V1.0\"  # (hypothetical name for a 7B general WizardCoder)\n",
        "# If the above is not available, one could use WizardCoder-15B-v1.0 with 4-bit as an alternative.\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    device_map=\"auto\",\n",
        "    load_in_4bit=True,\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "def generate_response_wizard(prompt, max_new_tokens=256):\n",
        "    inputs = tokenizer(prompt, return_tensors='pt').to(model.device)\n",
        "    outputs = model.generate(**inputs, max_new_tokens=max_new_tokens,\n",
        "                              do_sample=False, temperature=0.2)\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "print(\"**Vulnerability Detection (Zero-shot)**\")\n",
        "print(generate_response_wizard(prompt_vuln_zeroshot))\n",
        "print(\"\\n**Vulnerability Detection (Chain-of-Thought)**\")\n",
        "print(generate_response_wizard(prompt_vuln_cot))\n",
        "print(\"\\n**Functional Validation (Zero-shot)**\")\n",
        "print(generate_response_wizard(prompt_func_zeroshot))\n",
        "print(\"\\n**Functional Validation (Chain-of-Thought)**\")\n",
        "print(generate_response_wizard(prompt_func_cot))\n",
        "\n",
        "# Cleanup\n",
        "del model, tokenizer\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "print(\"\\n[Model memory cleared]\")\n"
      ],
      "metadata": {
        "id": "4YRWcy0AM9JF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 5 - Mistral 7B Instruct"
      ],
      "metadata": {
        "id": "dUxL2UuJHsEB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    device_map=\"auto\",\n",
        "    load_in_4bit=True,\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "def format_mistral_prompt(user_prompt):\n",
        "    # Mistral instruct requires wrapping the user prompt in [INST] tags, and starting with <s>\n",
        "    return f\"<s>[INST] {user_prompt} [/INST]\"\n",
        "\n",
        "def generate_response_mistral(user_prompt, max_new_tokens=256):\n",
        "    prompt = format_mistral_prompt(user_prompt)\n",
        "    inputs = tokenizer(prompt, return_tensors='pt').to(model.device)\n",
        "    outputs = model.generate(**inputs, max_new_tokens=max_new_tokens,\n",
        "                              do_sample=False, temperature=0.2)\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "print(\"**Vulnerability Detection (Zero-shot)**\")\n",
        "print(generate_response_mistral(\"Analyze the following Java code for security vulnerabilities:\\n```java\\n\" + code_vuln_snippet + \"\\n```\"))\n",
        "print(\"\\n**Vulnerability Detection (Chain-of-Thought)**\")\n",
        "print(generate_response_mistral(\"Analyze the Java code below for vulnerabilities. Think step by step and explain your reasoning.\\n```java\\n\" + code_vuln_snippet + \"\\n```\"))\n",
        "print(\"\\n**Functional Validation (Zero-shot)**\")\n",
        "print(generate_response_mistral(\"The following code is meant to securely store a password. Does it do so successfully?\\n```java\\n\" + code_func_snippet + \"\\n```\"))\n",
        "print(\"\\n**Functional Validation (Chain-of-Thought)**\")\n",
        "print(generate_response_mistral(\"Is the following Java function properly implementing secure password storage as intended? Provide a step-by-step analysis and conclusion.\\n```java\\n\" + code_func_snippet + \"\\n```\"))\n",
        "\n",
        "# Cleanup\n",
        "del model, tokenizer\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "print(\"\\n[Model memory cleared]\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "34b03e5b806c47a5b1f6f7edffe4a4ed",
            "a0a76ea35dbd45269335a005c0296f38",
            "c8cb1b7d4dcb485bad01bccb753c0606",
            "9f824cf395f640a98f4575486e3ba345",
            "284b20dcd8274f96b0d4eb014ce699c0",
            "c1f966bf4452406fac739f0ed763a186",
            "fb3a70185d5146a39ace44f0d5c35172",
            "37fcddde13a943d0a757e5572e5f4da3",
            "367b4e407a0548579f433b47fc0b8621",
            "5773428c1b6b4d2a953ef855e0817ac8",
            "1e5339469881498b9d783ddbcd8f371c",
            "6d7f9c73d61148abb4d916177bcb821c",
            "04091462af2a40ae8ce19702869f5ebf",
            "289cfd1916844b99b096df1dac6a21d6",
            "7bdceb2f47ac4065bb8d8fa951324571",
            "703351064b234fc6a552d70652c05949",
            "307861d44e6440bab2e111ccfe5793d9",
            "7ddc7811705f459c8f399481407f127e",
            "8a83eb9c7e284ccb88029872cbefdfd8",
            "1401ccd944eb4931a8727983c8b86aa3",
            "6f5e400fab8046c2a1f0d0772d52ad90",
            "703723bfa5144a928418707603d1c3dc",
            "9a1fba05581b43c78eaf503de3feb2ad",
            "f05ec41faf55488f9ccf11dc907074f1",
            "0a02584712704832afea2effffee344a",
            "8a0b699213cf4a789a62f3b22b002c92",
            "188cc475e63b452bbeb6e0a5ab2f085a",
            "dda468d3c40c4265b020634f9f247731",
            "ac45a3c7ff1f406ca9234bb1f2ee5994",
            "b8751104d3a847fa91659a579d2ff7fe",
            "94de4e1c14264e27ade768851b9902c6",
            "025ebad9782e4ae3a7a8b92726874056",
            "13ae232281c94d789cc0c9d259650d1b",
            "16d2842b061c4cc9b713a99fc6261ab4",
            "e54b2dfaf4814e3cbc1de0c53e792c8c",
            "2c12ba71d6484c67bf5232a4a32c8eb5",
            "d0363f8d8cbc4402a2a2a8c7beba8165",
            "c793fdf1f95646db96aac028974addfb",
            "f1ad7ce9eed24e1e9998bc73e6f8d2f1",
            "867c7b1235434eb5b3fa29651bba605a",
            "9717a4d37b00483c871de3e4b1b6767c",
            "02608488ad0d4ac196859338de90a85b",
            "f16e2a50d1d14738ab5fdcbfff0dc9b5",
            "e27efbf9fb804491b4a76acc67cf232a",
            "21b2e3ca06aa454894a722785d7a964d",
            "3282af011f4443f3a784f80dfc7bcf15",
            "03265358dc4f4b22bf6303c6c9a38450",
            "f2ae135f41bb4d13a2b5b56beb8bcac5",
            "fda26a0df7934073ae019de6b87299a8",
            "c3a19d92a2fd4d1bbea839561746d6bd",
            "274c6773f796491494316e35a860c5d1",
            "bcf8c28fe27743e29ed882a629e49003",
            "78e7c4eb434f4ba0bf21348f066c1877",
            "7efc6d2af695458793f9eb64da6e4b18",
            "a1d8f5c35808405d848acd5f70807d11",
            "366defa482d246779f73e3a7eea71bb0",
            "81781f799d7c4039bc7f9da3b2929cb8",
            "4bfb2f14a7964221a9f009299f9f180a",
            "78bd5d31c8634532ab2941111712657b",
            "eadf60cc89454b81ac3edd015ca4584f",
            "5ab6f65412714b3e87d1cd7580aa9e31",
            "e6ae5bda19db4f779aa9206f7040b964",
            "01ddb2e7aeb545ed9a0cf76f28a63737",
            "b6cb672104494087bcbe350e7c224172",
            "3807f77e2ed944279c55dff6ba727729",
            "231a208e74e443a6b90456e2f81e3f7f",
            "1d2d2e82209542cbb0e3ebc4727bbb1f",
            "bdcbc538fcc44b628da91addc10ea870",
            "c49cefac14964927be19cfadbcbe64e4",
            "e93b9d7b18f842f094c2e96a2f353658",
            "c08aae7b61e94f4f931053e442d551e3",
            "cc8b5a6956094951b9518eadc8a57f52",
            "bc9d1b37215f4590924126515c07b5d1",
            "233885eb8afc40ef99b97de9d37e1eee",
            "afdcfc2db2af445f85f7cf83d9489d9b",
            "4cbfa2663923463c8d2f5ccb7096fade",
            "226fd6638e7e4675a82378ca63d23146",
            "a193da819db8431e83102f40309bd0c3",
            "999faf226e2a464b8d0f88984d7a690b",
            "d0f840171e27408a91390cdbfa4b5cf8",
            "33cf3f55f6624708a1c6292ddb576885",
            "a025b8d7d5e3428a8e49a572a347c64a",
            "461e74189f6640869b48d6a65834cce6",
            "8f6097c6347c48cb833a009b5757cc30",
            "c659feb9e0364693b87aac4acdf73aa6",
            "c871f1a566a04096bc703a2407750af7",
            "466a056cf079447faccfd4ece64074bb",
            "5e54e463ee174e96a4223934196b6e5f",
            "bd05c402a7ee4db1accb0d9cd8703f73",
            "c1a3c142ab444a01a97c27eca41afe29",
            "f21072b33af341eca484283fb5c8bdd3",
            "9e3587581be043adadd66bf25158dda6",
            "ad1913705d324432877e4c225754a14c",
            "f23ed7548edb48ce8b269574de67a47b",
            "9cb4b41baa8a4be38fb44c0d63276428",
            "64e1e14d15384a35b32d5ce2c9e2dfec",
            "88c43710d83b49e8b527d3606f63fe89",
            "3dcf187f9c7043bab63c7086e05e4e2e",
            "a174fc84085748a4873c8632d102969f",
            "9b0f89bad9dc4f9eb5dc7ef004c84a1a",
            "6a31da77767d48bfa8c4b94ccebbf41a",
            "9f8ee74f2ab449908b9c038167755b09",
            "86f5b465c45f42c79c96893080d92b3d",
            "9493b25a51864a70a5de61141470623b",
            "e7ad1d8a75834ff2bae9f6f7f69a1bb4",
            "63a49258a48f4fa5bda59a37b2c59322",
            "6ba47508311d4187bf066e18516e4cb0",
            "2e4cddad330946fdbac4638847c7cc28",
            "c990489de0dd465fa0ef1cde9f5b9afa",
            "3cc021aa2a7443e8a4937b3809177587",
            "ee69a17e07c847b797fe2a4111ee362f",
            "c29c97fd13ae44e1b9455d3698090648",
            "50c6f7b4f39c486399eae393b7d45b86",
            "1da79c3db56b4b94bdc62890364ee93a",
            "b07b8f29037c49a58d5c3482edbf9eb8",
            "06c9bc88fe9a41918133c2c388281b08",
            "66afebd7de5f420c97e051c22abea88a",
            "c90f4a8f56bb4e799b59e51388620e31",
            "b3f464a4a2e14041bc84f48f4b747932",
            "a27f14e8a75a47f4bf0a60d056e6f409",
            "aab61a45b9394d55a15a1226bad6b188"
          ]
        },
        "id": "5n_z5auqNC4w",
        "outputId": "90fc8a2e-d43d-4a19-e4e1-af5db6f7b509"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/2.10k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34b03e5b806c47a5b1f6f7edffe4a4ed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d7f9c73d61148abb4d916177bcb821c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a1fba05581b43c78eaf503de3feb2ad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "16d2842b061c4cc9b713a99fc6261ab4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "21b2e3ca06aa454894a722785d7a964d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "366defa482d246779f73e3a7eea71bb0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d2d2e82209542cbb0e3ebc4727bbb1f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a193da819db8431e83102f40309bd0c3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bd05c402a7ee4db1accb0d9cd8703f73"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b0f89bad9dc4f9eb5dc7ef004c84a1a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee69a17e07c847b797fe2a4111ee362f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Vulnerability Detection (Zero-shot)**\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:629: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INST] Analyze the following Java code for security vulnerabilities:\n",
            "```java\n",
            "String productId = request.getParameter(\"id\");\n",
            "String query = \"SELECT * FROM products WHERE id = \" + productId;\n",
            "Statement st = connection.createStatement();\n",
            "ResultSet rs = st.executeQuery(query);\n",
            "while (rs.next()) {\n",
            "    String name = rs.getString(\"name\");\n",
            "    String description = rs.getString(\"description\");\n",
            "    // display product details\n",
            "}\n",
            "``` [/INST] The given Java code is vulnerable to SQL injection attacks. The `productId` variable is directly concatenated into the SQL query without any sanitization or validation. This means that an attacker can inject malicious SQL code into the `productId` parameter and potentially gain access to sensitive data or perform unauthorized actions on the database.\n",
            "\n",
            "To mitigate this vulnerability, the `productId` variable should be sanitized and validated before being used in the SQL query. One way to do this is to use parameterized queries, which allow you to specify placeholders for user input and automatically escape any special characters. Here's an example of how the code could be modified to use parameterized queries:\n",
            "```java\n",
            "String productId = request.getParameter(\"id\");\n",
            "if (productId == null || productId.isEmpty()) {\n",
            "    // handle invalid product ID\n",
            "} else {\n",
            "    String query = \"SELECT * FROM products WHERE id = ?\";\n",
            "    PreparedStatement st = connection.prepareStatement(query);\n",
            "    st.setString(1, productId);\n",
            "    ResultSet rs = st.executeQuery();\n",
            "    while (rs.next()) {\n",
            "        String name = rs\n",
            "\n",
            "**Vulnerability Detection (Chain-of-Thought)**\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INST] Analyze the Java code below for vulnerabilities. Think step by step and explain your reasoning.\n",
            "```java\n",
            "String productId = request.getParameter(\"id\");\n",
            "String query = \"SELECT * FROM products WHERE id = \" + productId;\n",
            "Statement st = connection.createStatement();\n",
            "ResultSet rs = st.executeQuery(query);\n",
            "while (rs.next()) {\n",
            "    String name = rs.getString(\"name\");\n",
            "    String description = rs.getString(\"description\");\n",
            "    // display product details\n",
            "}\n",
            "``` [/INST] This Java code appears to be vulnerable to SQL injection attacks. Here's a step-by-step analysis of the code:\n",
            "\n",
            "1. The `productId` variable is set to the value of the `id` parameter from the HTTP request. This is a good practice, as it ensures that the product ID is properly sanitized and validated before being used in the SQL query.\n",
            "2. The SQL query is constructed by concatenating the `productId` variable with a string literal. This is where the vulnerability lies. If the `productId` variable contains malicious SQL code, it can be injected into the query and potentially execute arbitrary SQL commands.\n",
            "3. The `Statement` and `ResultSet` objects are created and used to execute the query. This is standard Java code for interacting with a database.\n",
            "4. The `while` loop iterates through the results of the query and retrieves the `name` and `description` columns for each product. This is also standard Java code for working with a database.\n",
            "\n",
            "The vulnerability in this code is that the `productId` variable is not properly sanitized before being used in the SQL query. If an attacker can inject malicious\n",
            "\n",
            "**Functional Validation (Zero-shot)**\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INST] The following code is meant to securely store a password. Does it do so successfully?\n",
            "```java\n",
            "public static void storePasswordInsecurely(String username, String password) {\n",
            "    // This method is intended to securely store a password, but is it actually secure?\n",
            "    try {\n",
            "        Connection conn = DriverManager.getConnection(\"jdbc:mysql://localhost:3306/mydb\", \"username\", \"password\");\n",
            "        String query = \"INSERT INTO users (username, password) VALUES (?, ?)\";\n",
            "        PreparedStatement pstmt = conn.prepareStatement(query);\n",
            "        pstmt.setString(1, username);\n",
            "        pstmt.setString(2, password); // storing plain password\n",
            "        pstmt.executeUpdate();\n",
            "        pstmt.close();\n",
            "        conn.close();\n",
            "    } catch (SQLException e) {\n",
            "        e.printStackTrace();\n",
            "    }\n",
            "}\n",
            "``` [/INST] No, this code does not securely store a password. The password is stored in plain text in the database, which is not secure. A secure way to store a password would be to hash it using a strong hashing algorithm such as bcrypt or scrypt, and then store the hashed password in the database. This way, even if the database is compromised, the password cannot be easily retrieved.\n",
            "\n",
            "**Functional Validation (Chain-of-Thought)**\n",
            "[INST] Is the following Java function properly implementing secure password storage as intended? Provide a step-by-step analysis and conclusion.\n",
            "```java\n",
            "public static void storePasswordInsecurely(String username, String password) {\n",
            "    // This method is intended to securely store a password, but is it actually secure?\n",
            "    try {\n",
            "        Connection conn = DriverManager.getConnection(\"jdbc:mysql://localhost:3306/mydb\", \"username\", \"password\");\n",
            "        String query = \"INSERT INTO users (username, password) VALUES (?, ?)\";\n",
            "        PreparedStatement pstmt = conn.prepareStatement(query);\n",
            "        pstmt.setString(1, username);\n",
            "        pstmt.setString(2, password); // storing plain password\n",
            "        pstmt.executeUpdate();\n",
            "        pstmt.close();\n",
            "        conn.close();\n",
            "    } catch (SQLException e) {\n",
            "        e.printStackTrace();\n",
            "    }\n",
            "}\n",
            "``` [/INST] No, the Java function is not properly implementing secure password storage as intended. Here's a step-by-step analysis:\n",
            "1. The function takes two parameters: `username` and `password`.\n",
            "2. It creates a connection to a MySQL database using the `DriverManager.getConnection()` method.\n",
            "3. It creates a SQL query to insert the `username` and `password` into the `users` table.\n",
            "4. It creates a `PreparedStatement` object to execute the query.\n",
            "5. It sets the `username` and `password` values in the `PreparedStatement` using the `setString()` method.\n",
            "6. It executes the query using the `executeUpdate()` method.\n",
            "7. It closes the `PreparedStatement` and the database connection using the `close()` method.\n",
            "The problem with this function is that it stores the `password` in plain text in the database. This means that if an attacker gains access to the database, they can easily retrieve all the passwords.\n",
            "To properly store passwords securely, you should use a hashing algorithm to hash the password before storing it in the database. You should also use a salt\n",
            "\n",
            "[Model memory cleared]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Garbage Deletion Function"
      ],
      "metadata": {
        "id": "dr5VtHxMKJNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import torch\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "def cleanup_all():\n",
        "    \"\"\"\n",
        "    Frees up GPU memory and deletes local cache directories used by transformers and torch.\n",
        "    WARNING: This will remove local cache directories (e.g. models and tokenizers)\n",
        "             so they will need to be re-downloaded if needed later.\n",
        "    \"\"\"\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    cache_dirs = [\n",
        "        os.path.expanduser(\"~/.cache/huggingface/transformers\"),\n",
        "        os.path.expanduser(\"~/.cache/huggingface/hub\"),\n",
        "        os.path.expanduser(\"~/.cache/torch\")\n",
        "    ]\n",
        "\n",
        "    for cache_dir in cache_dirs:\n",
        "        if os.path.exists(cache_dir):\n",
        "            try:\n",
        "                shutil.rmtree(cache_dir)\n",
        "                print(f\"Deleted cache directory: {cache_dir}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Could not delete {cache_dir}: {e}\")\n",
        "        else:\n",
        "            print(f\"Cache directory does not exist: {cache_dir}\")\n",
        "\n",
        "    print(\"All caches and memory cleared.\")\n",
        "\n",
        "cleanup_all()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_saDeJJNKL-C",
        "outputId": "90d3c81f-84c8-4f6e-c2a4-f02fd7984d3e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cache directory does not exist: /root/.cache/huggingface/transformers\n",
            "Cache directory does not exist: /root/.cache/huggingface/hub\n",
            "Cache directory does not exist: /root/.cache/torch\n",
            "All caches and memory cleared.\n"
          ]
        }
      ]
    }
  ]
}